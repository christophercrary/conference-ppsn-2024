{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9cb24e",
   "metadata": {},
   "source": [
    "# Floating-Point Unit (FPU) Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627ac795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import iqr\n",
    "\n",
    "import primitive_sets\n",
    "\n",
    "root_dir = f'./results'\n",
    "\n",
    "# Seed random number generators for reproducibility.\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf3fbc",
   "metadata": {},
   "source": [
    "## Wrapper function for FPU\n",
    "\n",
    "Wrapper function to emulate the hardware-based floating-point unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae254e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.errstate(all='ignore')\n",
    "def fpu(primitive_set, sel, args, primal=None, differential=None):\n",
    "    \"\"\"Floating-point unit.\n",
    "    \n",
    "    The `primitive_set` parameter must be an indexable container \n",
    "    for a list of tuples, where each tuple is to define a primitive \n",
    "    function and its arity, in that order. The `sel` parameter must \n",
    "    be an integer representing the index of the function within \n",
    "    `primitive_set` that is to be computed. The inputs corresponding\n",
    "    to the relevant function are to be given by `*args[:arity]`, \n",
    "    with `arity` being the arity of the function.\n",
    "    \"\"\"\n",
    "    # The relevant function and its arity.\n",
    "    fn, arity = primitive_set[sel]\n",
    "    # Compute the function using the relevant arguments.\n",
    "    return fn(*args[:arity], primal=primal, differential=differential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e11a9",
   "metadata": {},
   "source": [
    "## Evaluating function error\n",
    "\n",
    "We use various error measures to compare each function within each primitive set to each function within the standard primitive set.\n",
    "\n",
    "We test various input domains, and for each primitive set, we use the same set of one million test cases, where the first 490 cases of this set are all choose-two combinations of the set of special inputs `{NaN, -Inf, +Inf, -0, +0, -1, +1}`, and where the remaining cases are randomly drawn (in a uniform manner) from the input domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4f741",
   "metadata": {},
   "source": [
    "### Helper functions for computing various error measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e4e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.errstate(all='ignore')\n",
    "def absolute_error(Y_true, Y_est):\n",
    "    \"\"\"Return absolute error.\n",
    "    \n",
    "    Special cases are handled.\n",
    "    \"\"\"\n",
    "    res = np.abs(Y_true - Y_est)\n",
    "\n",
    "    # Handle the case of both the desired/actual being \n",
    "    # equal to NaN.\n",
    "    res[np.isnan(Y_true) & np.isnan(Y_est)] = 0\n",
    "\n",
    "    # Handle the case of one of the desired/actual being\n",
    "    # equal to NaN, but not both.\n",
    "    res[~np.isnan(Y_true) & np.isnan(Y_est)] = np.inf\n",
    "    res[np.isnan(Y_true) & ~np.isnan(Y_est)] = np.inf\n",
    "\n",
    "    # Handle the case of both the desired/actual being equal \n",
    "    # to infinity, with the same sign. (If both are infinity \n",
    "    # with different signs, the error will be infinite.)\n",
    "    res[(Y_true == Y_est) & np.isinf(Y_true)] = 0\n",
    "    \n",
    "    return res\n",
    "\n",
    "@np.errstate(all='ignore')\n",
    "def relative_error(Y_true, Y_est):\n",
    "    \"\"\"Return relative error.\n",
    "    \n",
    "    Special cases are handled.\n",
    "    \"\"\"\n",
    "    res = np.abs(Y_true - Y_est) / np.abs(Y_true)\n",
    "\n",
    "    # Handle the case of both the desired/actual being \n",
    "    # equal to NaN.\n",
    "    res[np.isnan(Y_true) & np.isnan(Y_est)] = 0\n",
    "\n",
    "    # Handle the case of one of the desired/actual being\n",
    "    # equal to NaN, but not both.\n",
    "    res[~np.isnan(Y_true) & np.isnan(Y_est)] = np.inf\n",
    "    res[np.isnan(Y_true) & ~np.isnan(Y_est)] = np.inf\n",
    "\n",
    "    # Handle the case of both the desired/actual being\n",
    "    # equal to infinity, with the same sign.\n",
    "    res[(Y_true == Y_est) & np.isinf(Y_true)] = 0\n",
    "\n",
    "    # Handle the case of both the desired/actual being\n",
    "    # equal to infinity, but with different signs.\n",
    "    res[(Y_true != Y_est) & np.isinf(Y_true) & np.isinf(Y_est)] = np.inf\n",
    "\n",
    "    # Handle the case of the desired being equal to infinity \n",
    "    # and the actual being finite. (If the reverse is true,\n",
    "    # the relative error will already be infinite.)\n",
    "    res[np.isinf(Y_true) & np.isfinite(Y_est)] = np.inf\n",
    "\n",
    "    # Handle the case of the desired being equal to zero.\n",
    "    res[(Y_true == 0) & (Y_est == 0)] = 0\n",
    "    res[(Y_true == 0) & (Y_est != 0)] = np.inf\n",
    "\n",
    "    return res\n",
    "\n",
    "def round_sig(x, n):\n",
    "    \"\"\"Round to `n` significant digits.\"\"\"\n",
    "    res = x\n",
    "    if np.isfinite(res) and res != 0:\n",
    "        floor_ = np.floor(np.log10(res))\n",
    "        if np.isfinite(floor_):\n",
    "            res = round(res, -int(floor_) + (n - 1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b737df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function opcode to name mapping.\n",
    "function_names = {\n",
    "    0 : 'add',\n",
    "    1 : 'sub',\n",
    "    2 : 'mul',\n",
    "    3 : 'div',\n",
    "    4 : 'sin',\n",
    "    5 : 'cos',\n",
    "    6 : 'exp',\n",
    "    7 : 'log',\n",
    "    8 : 'sqrt',\n",
    "    9 : 'tanh',\n",
    "}\n",
    "\n",
    "# Primitive sets.\n",
    "primitive_sets_ = (\n",
    "    (primitive_sets.mad_16, 'mad_16'),\n",
    "    (primitive_sets.mad_10, 'mad_10'),\n",
    "    (primitive_sets.mad_04, 'mad_04'),\n",
    ")\n",
    "\n",
    "# Input domains.\n",
    "low = [-10,]\n",
    "high = [+10,]\n",
    "# low = [-10, -10000, -31875756.0, -3.4028235e+38]\n",
    "# high = [+10, +10000, +31875756.0, +3.4028235e+38]\n",
    "\n",
    "# Total number of input cases.\n",
    "n = 1000000\n",
    "# n = 1000\n",
    "# n = 10000\n",
    "\n",
    "# Number of significant digits for numeric statistics.\n",
    "d = 9\n",
    "\n",
    "# Dictionary to contain statistics for each primitive set.\n",
    "error_statistics = {name : {} for _, name in primitive_sets_}\n",
    "\n",
    "# Apply the test cases to each function and compute statistics.\n",
    "for primitive_set, ps_name in primitive_sets_:\n",
    "\n",
    "    # Number of functions in the current primitive set.\n",
    "    n_functions = len(primitive_set)\n",
    "\n",
    "    # Initialize dictionaries within `error_statistics[ps_name]`,\n",
    "    # which are to contain statistics for each function\n",
    "    # of `primitive_set`.\n",
    "    error_statistics[ps_name] = {name : {} for name in function_names.values()}\n",
    "\n",
    "    # Evaluate test cases for each input domain.\n",
    "    for low_, high_ in zip(low, high):\n",
    "        # Initialize input arrays to all possible combinations\n",
    "        # of special cases.\n",
    "        special_inputs = [np.nan, -np.inf, +np.inf, -0, +0, -1, +1]\n",
    "        X = np.asarray(special_inputs, dtype=np.float32)\n",
    "        X0, X1 = np.meshgrid(X, X, indexing='ij')\n",
    "        X0 = X0.ravel()\n",
    "        X1 = X1.ravel()\n",
    "\n",
    "        # Add uniformly random inputs to each input array.\n",
    "        n_sample = n - len(X0)\n",
    "        X0 = np.concatenate(\n",
    "            (X0, (np.random.uniform(\n",
    "                low=low_, high=high_, size=n_sample)).astype(np.float32)))\n",
    "        X1 = np.concatenate(\n",
    "            (X1, (np.random.uniform(\n",
    "                low=low_, high=high_, size=n_sample)).astype(np.float32)))\n",
    "        \n",
    "        for sel in function_names.keys():\n",
    "            # Extract the name of the current function.\n",
    "            f_name = function_names[sel]\n",
    "            _, arity = primitive_set[sel]\n",
    "\n",
    "            # Compute desired/actual function outputs.\n",
    "            Y_true = fpu(primitive_sets.standard, sel, [X0, X1])\n",
    "            Y_est = fpu(primitive_set, sel, [X0, X1])\n",
    "\n",
    "            # Absolute error.\n",
    "            abs_error = absolute_error(Y_true, Y_est)\n",
    "\n",
    "            # Statistics for absolute error.\n",
    "            abs_error_argmax = np.argmax(abs_error)\n",
    "            abs_error_max_test_case = (\n",
    "                f'x=({X0[abs_error_argmax]}, {X1[abs_error_argmax]}), '\n",
    "                f'y_true={Y_true[abs_error_argmax]}, '\n",
    "                f'y_est={Y_est[abs_error_argmax]}')\n",
    "            abs_error_max = round_sig(np.max(abs_error), d)\n",
    "            abs_error_med = round_sig(np.median(abs_error), d)\n",
    "            abs_error_mean = round_sig(np.mean(abs_error), d)\n",
    "            abs_error_min = round_sig(np.min(abs_error), d)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                abs_error_std = round_sig(np.std(abs_error), d)\n",
    "                abs_error_iqr = round_sig(iqr(abs_error), d)\n",
    "\n",
    "            # Relative error.\n",
    "            rel_error = relative_error(Y_true, Y_est)\n",
    "\n",
    "            # Convert relative error to percentage.\n",
    "            rel_error *= 100\n",
    "\n",
    "            # Statistics for relative error.\n",
    "            rel_error_argmax = np.argmax(rel_error)\n",
    "            rel_error_max_test_case = (\n",
    "                f'x=({X0[rel_error_argmax]}, {X1[rel_error_argmax]}), '\n",
    "                f'y_true={Y_true[rel_error_argmax]}, '\n",
    "                f'y_est={Y_est[rel_error_argmax]}')\n",
    "            rel_error_max = round_sig(np.max(rel_error), d)\n",
    "            rel_error_med = round_sig(np.median(rel_error), d)\n",
    "            rel_error_mean = round_sig(np.mean(rel_error), d)\n",
    "            rel_error_min = round_sig(np.min(rel_error), d)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                rel_error_std = round_sig(np.std(rel_error), d)\n",
    "                rel_error_iqr = round_sig(iqr(rel_error), d)\n",
    "\n",
    "            # Store statistics in dictionary.\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_ARGMAX', []).append(rel_error_argmax)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MAX_TEST_CASE', []).append(rel_error_max_test_case)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MAX', []).append(rel_error_max)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MED', []).append(rel_error_med)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MEAN', []).append(rel_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MIN', []).append(rel_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_STD', []).append(rel_error_std)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_IQR', []).append(rel_error_iqr)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_ARGMAX', []).append(abs_error_argmax)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MAX_TEST_CASE', []).append(abs_error_max_test_case)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MAX', []).append(abs_error_max)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MED', []).append(abs_error_med)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MEAN', []).append(abs_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MIN', []).append(abs_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_STD', []).append(abs_error_std)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_IQR', []).append(abs_error_iqr)\n",
    "            \n",
    "\n",
    "            # Compute desired/actual derivative outputs.\n",
    "            Y_true_p = fpu(\n",
    "                primitive_sets.standard, sel, [X0, X1],\n",
    "                primal=Y_true, differential=0)\n",
    "            Y_est_p = fpu(\n",
    "                primitive_set, sel, [X0, X1],\n",
    "                primal=Y_est, differential=0)\n",
    "            \n",
    "            if arity == 2:\n",
    "                # Compute second partial derivative.\n",
    "                Y_true_p_2 = fpu(\n",
    "                    primitive_sets.standard, sel, [X0, X1],\n",
    "                    primal=Y_true, differential=1)\n",
    "                Y_est_p_2 = fpu(\n",
    "                    primitive_set, sel, [X0, X1],\n",
    "                    primal=Y_est, differential=1)\n",
    "\n",
    "            # Absolute error.\n",
    "            abs_error = absolute_error(Y_true_p, Y_est_p)\n",
    "\n",
    "            if arity == 2:\n",
    "                # Add independent errors from second partial derivative.\n",
    "                abs_error += absolute_error(Y_true_p_2, Y_est_p_2)\n",
    "\n",
    "            # Statistics for absolute error.\n",
    "            abs_error_argmax = np.argmax(abs_error)\n",
    "            abs_error_max_test_case = (\n",
    "                f'x=({X0[abs_error_argmax]}, {X1[abs_error_argmax]}), '\n",
    "                f'y_true={Y_true_p[abs_error_argmax]}, '\n",
    "                f'y_est={Y_est_p[abs_error_argmax]}')\n",
    "            abs_error_max = round_sig(np.max(abs_error), d)\n",
    "            abs_error_med = round_sig(np.median(abs_error), d)\n",
    "            abs_error_mean = round_sig(np.mean(abs_error), d)\n",
    "            abs_error_min = round_sig(np.min(abs_error), d)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                abs_error_std = round_sig(np.std(abs_error), d)\n",
    "                abs_error_iqr = round_sig(iqr(abs_error), d)\n",
    "\n",
    "            # Relative error.\n",
    "            rel_error = relative_error(Y_true_p, Y_est_p)\n",
    "\n",
    "            if arity == 2:\n",
    "                # Add independent errors from second partial derivative.\n",
    "                rel_error += relative_error(Y_true_p_2, Y_est_p_2)\n",
    "\n",
    "            # Convert relative error to percentage.\n",
    "            rel_error *= 100\n",
    "\n",
    "            # Statistics for relative error.\n",
    "            rel_error_argmax = np.argmax(rel_error)\n",
    "            rel_error_max_test_case = (\n",
    "                f'x=({X0[rel_error_argmax]}, {X1[rel_error_argmax]}), '\n",
    "                f'y_true={Y_true_p[rel_error_argmax]}, '\n",
    "                f'y_est={Y_est_p[rel_error_argmax]}')\n",
    "            rel_error_max = round_sig(np.max(rel_error), d)\n",
    "            rel_error_med = round_sig(np.median(rel_error), d)\n",
    "            rel_error_mean = round_sig(np.mean(rel_error), d)\n",
    "            rel_error_min = round_sig(np.min(rel_error), d)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                rel_error_std = round_sig(np.std(rel_error), d)\n",
    "                rel_error_iqr = round_sig(iqr(rel_error), d)\n",
    "\n",
    "            # Store statistics in dictionary.\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_ARGMAX', []).append(rel_error_argmax)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MAX_TEST_CASE', []).append(rel_error_max_test_case)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MAX', []).append(rel_error_max)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MED', []).append(rel_error_med)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MEAN', []).append(rel_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_MIN', []).append(rel_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_STD', []).append(rel_error_std)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'REL_ERROR_IQR', []).append(rel_error_iqr)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_ARGMAX', []).append(abs_error_argmax)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MAX_TEST_CASE', []).append(abs_error_max_test_case)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MAX', []).append(abs_error_max)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MED', []).append(abs_error_med)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MEAN', []).append(abs_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_MIN', []).append(abs_error_mean)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_STD', []).append(abs_error_std)\n",
    "            error_statistics[ps_name][f_name].setdefault(\n",
    "                'ABS_ERROR_IQR', []).append(abs_error_iqr)\n",
    "\n",
    "\n",
    "# Write the relevant statistics to a CSV file.\n",
    "df = pd.DataFrame.from_dict(\n",
    "    {(i,j): error_statistics[i][j] \n",
    "     for i in error_statistics.keys() for j in error_statistics[i].keys()},\n",
    "    orient='index')\n",
    "df.to_excel(f'{root_dir}/error_statistics.xlsx', na_rep='NaN')\n",
    "df.to_csv(f'{root_dir}/error_statistics.csv', na_rep='NaN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eel6814",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
